"""
Script para baixar datasets p√∫blicos automaticamente.
Desenvolvido para TCC - Engenharia Mecatr√¥nica
"""
import os
import requests
import zipfile
from pathlib import Path
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def baixar_zenodo_pv01():
    """Baixa dataset Zenodo PV01 (drone images) - RECOMENDADO"""
    logger.info("üì• Baixando Zenodo PV01 Dataset...")
    
    url = "https://zenodo.org/record/5171712/files/PV01.zip"
    destino = Path("dados/datasets_publicos/zenodo_pv01.zip")
    destino.parent.mkdir(parents=True, exist_ok=True)
    
    try:
        logger.info(f"Fazendo download de {url}...")
        response = requests.get(url, stream=True)
        total = int(response.headers.get('content-length', 0))
        
        if total > 0:
            logger.info(f"Tamanho do arquivo: {total / (1024*1024):.1f} MB")
        
        with open(destino, 'wb') as f:
            downloaded = 0
            for data in response.iter_content(chunk_size=8192):
                f.write(data)
                downloaded += len(data)
                if total > 0:
                    percent = (downloaded / total) * 100
                    print(f"\rProgresso: {percent:.1f}%", end="", flush=True)
        
        print()  # Nova linha ap√≥s progress bar
        logger.info(f"‚úÖ Download completo: {destino}")
        
        # Extrair
        logger.info("üì¶ Extraindo arquivos...")
        with zipfile.ZipFile(destino, 'r') as zip_ref:
            zip_ref.extractall(destino.parent / "pv01")
        
        logger.info("‚úÖ Extra√≠do com sucesso!")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao baixar Zenodo PV01: {e}")
        return False

def baixar_kaggle_dust_detection():
    """Baixa dataset Kaggle de detec√ß√£o de poeira"""
    logger.info("üì• Baixando Kaggle Dust Detection...")
    
    try:
        # Verificar se kaggle CLI est√° configurado
        import subprocess
        
        # Testar autentica√ß√£o Kaggle
        result = subprocess.run(['kaggle', 'datasets', 'list'], capture_output=True, text=True)
        if result.returncode != 0:
            logger.warning("‚ö†Ô∏è Kaggle CLI n√£o configurado. Configure com: kaggle config")
            logger.info("üìù Passos para configurar:")
            logger.info("1. Ir em kaggle.com/settings")
            logger.info("2. Criar API token (baixa kaggle.json)")
            logger.info("3. Mover para ~/.kaggle/kaggle.json")
            logger.info("4. Definir permiss√µes: chmod 600 ~/.kaggle/kaggle.json")
            return False
        
        # Criar diret√≥rio de destino
        destino_dir = Path("dados/datasets_publicos")
        destino_dir.mkdir(parents=True, exist_ok=True)
        
        # Download via Kaggle CLI
        logger.info("Baixando via Kaggle CLI...")
        os.system("kaggle datasets download -d hemanthsai7/solar-panel-dust-detection -p dados/datasets_publicos/")
        
        # Extrair
        zip_path = Path("dados/datasets_publicos/solar-panel-dust-detection.zip")
        if zip_path.exists():
            logger.info("üì¶ Extraindo arquivos...")
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall("dados/datasets_publicos/kaggle_dust")
            
            # Remover zip ap√≥s extra√ß√£o
            zip_path.unlink()
            logger.info("‚úÖ Kaggle dataset baixado e extra√≠do!")
            return True
        else:
            logger.error("‚ùå Arquivo zip n√£o encontrado ap√≥s download")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Erro ao baixar Kaggle dataset: {e}")
        return False

def baixar_roboflow_solar_panels(api_key: str = None):
    """Baixa dataset Roboflow via API (opcional)"""
    if not api_key:
        logger.info("üîë Pulei download Roboflow (API key n√£o fornecida)")
        return False
    
    logger.info("üì• Baixando Roboflow Solar Panels...")
    
    try:
        from roboflow import Roboflow
        
        rf = Roboflow(api_key=api_key)
        project = rf.workspace("roboflow-100").project("solar-panels-taxvb")
        dataset = project.version(2).download("yolov8", 
                                              location="dados/datasets_publicos/roboflow_solar")
        
        logger.info("‚úÖ Roboflow dataset baixado!")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao baixar Roboflow dataset: {e}")
        return False

def converter_zenodo_para_yolo():
    """Converte m√°scaras de segmenta√ß√£o do Zenodo para formato YOLO"""
    logger.info("üîÑ Convertendo Zenodo para formato YOLO...")
    
    try:
        import cv2
        import numpy as np
        from pathlib import Path
        
        src_dir = Path("dados/datasets_publicos/pv01")
        if not src_dir.exists():
            logger.error("‚ùå Diret√≥rio PV01 n√£o encontrado. Execute download primeiro.")
            return False
        
        dst_dir = Path("dados/plantas_completas/imagens")
        dst_dir.mkdir(parents=True, exist_ok=True)
        
        (dst_dir / "train").mkdir(exist_ok=True)
        (dst_dir / "val").mkdir(exist_ok=True)
        
        annotations_dir = Path("dados/plantas_completas/anotacoes")
        annotations_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info("Processando imagens...")
        processed = 0
        
        for img_path in list(src_dir.glob("*.bmp"))[:50]:  # Limitar para teste
            label_path = img_path.parent / f"{img_path.stem}_label.bmp"
            
            if not label_path.exists():
                continue
            
            # Ler imagem e m√°scara
            img = cv2.imread(str(img_path))
            mask = cv2.imread(str(label_path), cv2.IMREAD_GRAYSCALE)
            
            if img is None or mask is None:
                continue
            
            # Encontrar contornos (cada painel)
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            h, w = img.shape[:2]
            yolo_annotations = []
            
            for contour in contours:
                # Bounding box do contorno
                x, y, bw, bh = cv2.boundingRect(contour)
                
                # Ignorar boxes muito pequenos
                if bw < 20 or bh < 20:
                    continue
                
                # Converter para formato YOLO (normalizado)
                x_center = (x + bw/2) / w
                y_center = (y + bh/2) / h
                width = bw / w
                height = bh / h
                
                # Classe 0 = m√≥dulo fotovoltaico
                yolo_annotations.append(f"0 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}")
            
            if yolo_annotations:  # Apenas se encontrou m√≥dulos
                # Salvar imagem
                dst_path = dst_dir / "train" / img_path.name
                cv2.imwrite(str(dst_path), img)
                
                # Salvar anota√ß√µes YOLO
                annotation_path = annotations_dir / f"{img_path.stem}.txt"
                with open(annotation_path, 'w') as f:
                    f.write('\n'.join(yolo_annotations))
                
                processed += 1
                if processed % 10 == 0:
                    print(f"\rProcessadas: {processed} imagens", end="", flush=True)
        
        print()  # Nova linha
        logger.info(f"‚úÖ Convers√£o completa! {processed} imagens processadas.")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erro na convers√£o: {e}")
        return False

def criar_dataset_yaml():
    """Cria arquivo dataset.yaml para YOLOv8"""
    logger.info("üìù Criando dataset.yaml...")
    
    try:
        import os
        
        # Obter path absoluto
        current_dir = os.path.abspath(".")
        data_dir = os.path.join(current_dir, "dados", "plantas_completas")
        
        yaml_content = f"""# Dataset de pain√©is solares para YOLOv8
# TCC - Engenharia Mecatr√¥nica
path: {data_dir}
train: imagens/train
val: imagens/val

nc: 1  # n√∫mero de classes
names: ['modulo']  # painel fotovoltaico
"""
        
        with open("dados/plantas_completas/dataset.yaml", 'w') as f:
            f.write(yaml_content)
        
        logger.info("‚úÖ dataset.yaml criado!")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao criar dataset.yaml: {e}")
        return False

def organizar_kaggle_para_classificacao():
    """Organiza dataset Kaggle para classifica√ß√£o EfficientNet"""
    logger.info("üóÇÔ∏è Organizando dataset Kaggle para classifica√ß√£o...")
    
    try:
        src_dir = Path("dados/datasets_publicos/kaggle_dust")
        dst_limpo = Path("dados/modulos_individuais/limpo")
        dst_sujo = Path("dados/modulos_individuais/sujo")
        
        if not src_dir.exists():
            logger.warning("‚ö†Ô∏è Dataset Kaggle n√£o encontrado")
            return False
        
        # Criar diret√≥rios de destino
        dst_limpo.mkdir(parents=True, exist_ok=True)
        dst_sujo.mkdir(parents=True, exist_ok=True)
        
        # Mover arquivos (assumindo estrutura padr√£o)
        logger.info("Organizando arquivos...")
        
        # Procurar pastas clean/dusty ou similar
        for folder in src_dir.iterdir():
            if folder.is_dir():
                if 'clean' in folder.name.lower():
                    for img in folder.glob("*.jpg"):
                        dst_path = dst_limpo / img.name
                        shutil.copy2(img, dst_path)
                
                elif 'dust' in folder.name.lower() or 'dirty' in folder.name.lower():
                    for img in folder.glob("*.jpg"):
                        dst_path = dst_sujo / img.name
                        shutil.copy2(img, dst_path)
        
        # Contar arquivos
        limpo_count = len(list(dst_limpo.glob("*.jpg")))
        sujo_count = len(list(dst_sujo.glob("*.jpg")))
        
        logger.info(f"‚úÖ Organiza√ß√£o completa!")
        logger.info(f"   Limpos: {limpo_count} imagens")
        logger.info(f"   Sujos: {sujo_count} imagens")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao organizar dataset: {e}")
        return False

def main():
    """Fun√ß√£o principal de download e prepara√ß√£o"""
    print("=" * 80)
    print("üöÄ DOWNLOAD AUTOM√ÅTICO DE DATASETS P√öBLICOS")
    print("   TCC - Engenharia Mecatr√¥nica")
    print("=" * 80)
    
    success_count = 0
    total_tasks = 4
    
    # 1. Baixar Zenodo PV01 (detec√ß√£o)
    if baixar_zenodo_pv01():
        success_count += 1
    
    # 2. Converter Zenodo para YOLO
    if converter_zenodo_para_yolo():
        success_count += 1
    
    # 3. Criar dataset.yaml
    if criar_dataset_yaml():
        success_count += 1
    
    # 4. Baixar Kaggle (classifica√ß√£o)
    if baixar_kaggle_dust_detection():
        success_count += 1
        organizar_kaggle_para_classificacao()
    
    # 5. Roboflow (opcional)
    # api_key = os.getenv("ROBOFLOW_API_KEY")
    # baixar_roboflow_solar_panels(api_key)
    
    print("\n" + "=" * 80)
    print(f"üìä RESUMO: {success_count}/{total_tasks} tarefas conclu√≠das")
    
    if success_count == total_tasks:
        print("‚úÖ TODOS OS DATASETS BAIXADOS E PREPARADOS COM SUCESSO!")
        print("\nüéØ PR√ìXIMOS PASSOS:")
        print("1. cd backend && pip install -r requirements.txt")
        print("2. python -m aplicacao.principal")
        print("3. cd ../frontend && npm install && npm run dev")
        print("4. Acesse http://localhost:5173")
    else:
        print("‚ö†Ô∏è Algumas tarefas falharam. Verifique os logs acima.")
    
    print("=" * 80)

if __name__ == "__main__":
    import shutil  # Import aqui para evitar conflito
    main()
