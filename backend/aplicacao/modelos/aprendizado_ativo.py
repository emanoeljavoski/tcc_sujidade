"""
Sistema de Active Learning para Expansibilidade do Dataset
Desenvolvido para TCC - Engenharia Mecatr√¥nica

FUNCIONALIDADE:
- Sugere quais imagens novas s√£o mais importantes para anotar
- Usa MC Dropout para medir incerteza do modelo
- Prioriza imagens com maior incerteza (maximiza ganho de performance)
- Sistema expans√≠vel que se adapta quando conseguir mais imagens
"""
import torch
import torch.nn as nn
import numpy as np
import logging
from typing import List, Tuple, Dict, Any
from PIL import Image
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json
import cv2
import os

# Import dos modelos
from .classificador import ClassificadorSujidade
from .ordinal_classifier import ClassificadorOrdinal

logger = logging.getLogger(__name__)

class ActiveLearningModule:
    """
    Sistema expans√≠vel com active learning.
    Sugere quais imagens novas s√£o mais importantes anotar.
    
    Estrat√©gias implementadas:
    1. MC Dropout - Mede incerteza via predi√ß√µes estoc√°sticas
    2. Entropia - Prioriza predi√ß√µes mais incertas
    3. Margin Sampling - Prioriza predi√ß√µes com menor margem
    4. Committee - Usa m√∫ltiplos modelos (ensemble)
    """
    
    def __init__(self, modelo_treinado, strategy='mc_dropout'):
        """
        Inicializa m√≥dulo de active learning.
        
        Args:
            modelo_treinado: Modelo treinado (ClassificadorSujidade ou ClassificadorOrdinal)
            strategy: Estrat√©gia de active learning ('mc_dropout', 'entropy', 'margin', 'committee')
        """
        self.modelo = modelo_treinado
        self.modelo_original = modelo_treinado  # Backup
        self.dispositivo = modelo_treinado.dispositivo
        self.strategy = strategy
        
        logger.info(f"ü§ñ Inicializando Active Learning com estrat√©gia: {strategy}")
        
        # Configurar modelo para MC Dropout se necess√°rio
        if strategy == 'mc_dropout':
            self._configurar_mc_dropout()
        
        # Para committee, criar ensemble de modelos
        if strategy == 'committee':
            self._criar_committee()
    
    def _configurar_mc_dropout(self):
        """
        Configura modelo para MC Dropout.
        Ativa dropout durante infer√™ncia para medi√ß√£o de incerteza.
        """
        logger.info("üé≤ Configurando MC Dropout...")
        
        # For√ßa dropout ativo durante infer√™ncia
        def set_dropout_train(m):
            if isinstance(m, nn.Dropout):
                m.train()
        
        self.modelo.modelo.apply(set_dropout_train)
        logger.info("‚úÖ Dropout configurado para modo MC")
    
    def _criar_committee(self):
        """
        Cria committee de modelos para ensemble.
        Usa diferentes checkpoints do treinamento.
        """
        logger.info("üë• Criando committee de modelos...")
        
        # Procurar por diferentes folds salvos
        modelos_committee = []
        folds_dir = Path('modelos_salvos')
        
        if folds_dir.exists():
            fold_files = list(folds_dir.glob('fold_*_efficientnet_b4.pth'))
            fold_files.sort()
            
            # Usar at√© 5 modelos diferentes
            for i, fold_file in enumerate(fold_files[:5]):
                try:
                    modelo_committee = ClassificadorSujidade(num_classes=self.modelo.num_classes)
                    modelo_committee.carregar_modelo(str(fold_file))
                    modelos_committee.append(modelo_committee)
                    logger.info(f"‚úÖ Carregado modelo do fold {i+1}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro ao carregar {fold_file}: {e}")
        
        if len(modelos_committee) == 0:
            # Fallback: usar o mesmo modelo com diferentes configura√ß√µes
            logger.warning("‚ö†Ô∏è Nenhum modelo de fold encontrado, usando modelo original")
            modelos_committee = [self.modelo]
        
        self.committee = modelos_committee
        logger.info(f"üë• Committee criado com {len(self.committee)} modelos")
    
    def predict_with_uncertainty(self, imagem, n_samples=10):
        """
        Predi√ß√£o + medida de incerteza usando estrat√©gia selecionada.
        
        Args:
            imagem: Imagem para analisar
            n_samples: N√∫mero de amostras para MC Dropout
            
        Returns:
            dict: Predi√ß√£o e m√©tricas de incerteza
        """
        try:
            if self.strategy == 'mc_dropout':
                return self._predict_mc_dropout(imagem, n_samples)
            elif self.strategy == 'entropy':
                return self._predict_entropy(imagem)
            elif self.strategy == 'margin':
                return self._predict_margin(imagem)
            elif self.strategy == 'committee':
                return self._predict_committee(imagem)
            else:
                raise ValueError(f"Estrat√©gia desconhecida: {self.strategy}")
                
        except Exception as e:
            logger.error(f"‚ùå Erro na predi√ß√£o com incerteza: {e}")
            return {
                'prediction': 0,
                'uncertainty': 1.0,
                'confidence': 0.0,
                'error': str(e)
            }
    
    def _predict_mc_dropout(self, imagem, n_samples=10):
        """
        Predi√ß√£o com MC Dropout.
        Ativa dropout em infer√™ncia e faz m√∫ltiplas predi√ß√µes.
        """
        self.modelo.modelo.eval()
        
        # For√ßa dropout ativo
        def set_dropout_train(m):
            if isinstance(m, nn.Dropout):
                m.train()
        
        self.modelo.modelo.apply(set_dropout_train)
        
        # M√∫ltiplas predi√ß√µes estoc√°sticas
        predictions = []
        probabilidades = []
        
        with torch.no_grad():
            img_tensor = self.modelo.preprocessar_imagem(imagem)
            
            for _ in range(n_samples):
                outputs = self.modelo.modelo(img_tensor)
                probs = torch.nn.functional.softmax(outputs, dim=1)
                pred = torch.argmax(probs, dim=1).item()
                predictions.append(pred)
                probabilidades.append(probs.cpu().numpy()[0])
        
        # Estat√≠sticas
        predictions = np.array(predictions)
        probabilidades = np.array(probabilidades)
        
        # Predi√ß√£o final (majority vote)
        unique, counts = np.unique(predictions, return_counts=True)
        final_prediction = unique[np.argmax(counts)]
        
        # Medidas de incerteza
        mean_probs = np.mean(probabilidades, axis=0)
        std_probs = np.std(probabilidades, axis=0)
        
        # Entropia como incerteza
        entropy = -np.sum(mean_probs * np.log(mean_probs + 1e-10))
        
        # Confian√ßa baseada na consist√™ncia das predi√ß√µes
        confidence = np.max(counts) / n_samples
        
        # Incerteza baseada na vari√¢ncia
        uncertainty = np.mean(std_probs)
        
        return {
            'prediction': int(final_prediction),
            'uncertainty': float(uncertainty),
            'confidence': float(confidence),
            'entropy': float(entropy),
            'mean_probabilities': mean_probs.tolist(),
            'std_probabilities': std_probs.tolist(),
            'prediction_distribution': dict(zip(unique, counts.tolist()))
        }
    
    def _predict_entropy(self, imagem):
        """
        Predi√ß√£o com incerteza baseada em entropia.
        """
        resultado = self.modelo.classificar(imagem)
        
        if 'erro' in resultado:
            return {
                'prediction': 0,
                'uncertainty': 1.0,
                'confidence': 0.0,
                'error': resultado['erro']
            }
        
        probs = np.array(list(resultado['probabilidades'].values())) / 100
        
        # Entropia
        entropy = -np.sum(probs * np.log(probs + 1e-10))
        
        # Normalizar entropia para [0, 1]
        max_entropy = np.log(len(probs))
        normalized_entropy = entropy / max_entropy
        
        return {
            'prediction': resultado['classe_idx'],
            'uncertainty': float(normalized_entropy),
            'confidence': resultado['confianca'] / 100,
            'entropy': float(entropy),
            'probabilities': probs.tolist()
        }
    
    def _predict_margin(self, imagem):
        """
        Predi√ß√£o com incerteza baseada em margin sampling.
        Margem = diferen√ßa entre as 2 maiores probabilidades.
        """
        resultado = self.modelo.classificar(imagem)
        
        if 'erro' in resultado:
            return {
                'prediction': 0,
                'uncertainty': 1.0,
                'confidence': 0.0,
                'error': resultado['erro']
            }
        
        probs = np.array(list(resultado['probabilidades'].values())) / 100
        
        # Ordenar probabilidades
        sorted_probs = np.sort(probs)[::-1]
        
        # Margin = diferen√ßa entre top 2
        if len(sorted_probs) >= 2:
            margin = sorted_probs[0] - sorted_probs[1]
        else:
            margin = 0.0
        
        # Incerteza = 1 - margin (quanto menor a margem, mais incerto)
        uncertainty = 1 - margin
        
        return {
            'prediction': resultado['classe_idx'],
            'uncertainty': float(uncertainty),
            'confidence': resultado['confianca'] / 100,
            'margin': float(margin),
            'probabilities': probs.tolist()
        }
    
    def _predict_committee(self, imagem):
        """
        Predi√ß√£o usando committee de modelos.
        Mede discord√¢ncia entre diferentes modelos.
        """
        if not hasattr(self, 'committee'):
            logger.warning("‚ö†Ô∏è Committee n√£o dispon√≠vel, usando modelo √∫nico")
            return self._predict_entropy(imagem)
        
        predictions = []
        confiancas = []
        probabilidades = []
        
        # Predi√ß√µes de cada modelo do committee
        for modelo in self.committee:
            resultado = modelo.classificar(imagem)
            if 'erro' not in resultado:
                predictions.append(resultado['classe_idx'])
                confiancas.append(resultado['confianca'] / 100)
                probs = np.array(list(resultado['probabilidades'].values())) / 100
                probabilidades.append(probs)
        
        if len(predictions) == 0:
            return {
                'prediction': 0,
                'uncertainty': 1.0,
                'confidence': 0.0,
                'error': 'Nenhuma predi√ß√£o bem-sucedida'
            }
        
        # Predi√ß√£o final (majority vote)
        unique, counts = np.unique(predictions, return_counts=True)
        final_prediction = unique[np.argmax(counts)]
        
        # Medidas de incerteza
        vote_entropy = -np.sum((counts / len(predictions)) * np.log(counts / len(predictions) + 1e-10))
        
        # Discord√¢ncia nas probabilidades
        if len(probabilidades) > 1:
            mean_probs = np.mean(probabilidades, axis=0)
            std_probs = np.std(probabilidades, axis=0)
            prob_disagreement = np.mean(std_probs)
        else:
            prob_disagreement = 0.0
        
        # Confian√ßa baseada na concord√¢ncia do voto
        vote_confidence = np.max(counts) / len(predictions)
        
        # Incerteza combinada
        uncertainty = (vote_entropy / np.log(len(unique)) + prob_disagreement) / 2
        
        return {
            'prediction': int(final_prediction),
            'uncertainty': float(uncertainty),
            'confidence': float(vote_confidence),
            'vote_entropy': float(vote_entropy),
            'prob_disagreement': float(prob_disagreement),
            'committee_agreement': dict(zip(unique.tolist(), counts.tolist())),
            'mean_probabilities': mean_probs.tolist() if len(probabilidades) > 1 else probabilidades[0].tolist()
        }
    
    def suggest_samples(self, novas_imagens, n=20, diversity_factor=0.3):
        """
        Analisa imagens novas e sugere as N mais importantes para anotar.
        Prioriza imagens onde modelo tem maior incerteza.
        
        Args:
            novas_imagens: Lista de imagens para analisar
            n: N√∫mero de imagens a sugerir
            diversity_factor: Fator para diversificar sele√ß√£o (0-1)
            
        Returns:
            dict: Sugest√µes com an√°lises detalhadas
        """
        logger.info(f"üéØ Analisando {len(novas_imagens)} imagens para active learning...")
        
        if len(novas_imagens) == 0:
            return {
                'total_imagens': 0,
                'sugestoes': [],
                'message': 'Nenhuma imagem para analisar'
            }
        
        # Analisar cada imagem
        analises = []
        
        for idx, img in enumerate(novas_imagens):
            try:
                resultado = self.predict_with_uncertainty(img)
                
                analise = {
                    'indice': idx,
                    'incerteza': resultado['uncertainty'],
                    'confianca': resultado['confidence'],
                    'predicao': resultado['prediction'],
                    'estrategia': self.strategy
                }
                
                # Adicionar m√©tricas espec√≠ficas da estrat√©gia
                if 'entropy' in resultado:
                    analise['entropia'] = resultado['entropy']
                if 'margin' in resultado:
                    analise['margem'] = resultado['margin']
                if 'vote_entropy' in resultado:
                    analise['entropia_voto'] = resultado['vote_entropy']
                
                analises.append(analise)
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erro ao analisar imagem {idx}: {e}")
                analises.append({
                    'indice': idx,
                    'incerteza': 1.0,  # M√°xima incerteza em caso de erro
                    'confianca': 0.0,
                    'predicao': 0,
                    'erro': str(e)
                })
        
        # Ordenar por incerteza (maiores primeiro)
        analises.sort(key=lambda x: x['incerteza'], reverse=True)
        
        # Aplicar diversifica√ß√£o se solicitado
        if diversity_factor > 0 and len(analises) > n:
            analises = self._diversify_selection(analises, n, diversity_factor)
        else:
            analises = analises[:n]
        
        # Preparar resultado
        sugestoes = []
        for i, analise in enumerate(analises):
            sugestao = {
                'rank': i + 1,
                'indice_imagem': analise['indice'],
                'prioridade': 'ALTA' if analise['incerteza'] > 0.7 else 'MEDIA' if analise['incerteza'] > 0.4 else 'BAIXA',
                'incerteza': round(analise['incerteza'], 3),
                'confianca': round(analise['confianca'], 3),
                'predicao': analise['predicao'],
                'razao': self._get_prioridade_reason(analise)
            }
            
            # Adicionar m√©tricas espec√≠ficas
            if 'entropia' in analise:
                sugestao['entropia'] = round(analise['entropia'], 3)
            if 'margem' in analise:
                sugestao['margem'] = round(analise['margem'], 3)
            
            sugestoes.append(sugestao)
        
        # Estat√≠sticas gerais
        incertezas = [a['incerteza'] for a in analises]
        confiancas = [a['confianca'] for a in analises]
        
        resultado = {
            'total_imagens': len(novas_imagens),
            'imagens_sugeridas': len(sugestoes),
            'estrategia': self.strategy,
            'sugestoes': sugestoes,
            'estatisticas': {
                'incerteza_media': np.mean(incertezas),
                'incerteza_max': np.max(incertezas),
                'incerteza_min': np.min(incertezas),
                'confianca_media': np.mean(confiancas),
                'distribuicao_prioridades': {
                    'ALTA': sum(1 for s in sugestoes if s['prioridade'] == 'ALTA'),
                    'MEDIA': sum(1 for s in sugestoes if s['prioridade'] == 'MEDIA'),
                    'BAIXA': sum(1 for s in sugestoes if s['prioridade'] == 'BAIXA')
                }
            },
            'message': f"Anote estas {len(sugestoes)} imagens primeiro para maximizar ganho de performance"
        }
        
        # Log das top sugest√µes
        logger.info(f"\nüéØ TOP {min(10, len(sugestoes))} IMAGENS PRIORIT√ÅRIAS:")
        for i, sugestao in enumerate(sugestoes[:10]):
            logger.info(
                f"   {i+1}. Imagem #{sugestao['indice_imagem']}: "
                f"Incerteza={sugestao['incerteza']:.3f}, "
                f"Prioridade={sugestao['prioridade']}, "
                f"Predi√ß√£o={sugestao['predicao']}"
            )
        
        return resultado
    
    def _diversify_selection(self, analises, n, diversity_factor):
        """
        Diversifica sele√ß√£o para evitar clustering de amostras similares.
        """
        if len(analises) <= n:
            return analises
        
        # Sele√ß√£o baseada em incerteza e diversidade
        selecionadas = []
        restantes = analises.copy()
        
        # Primeiro, selecionar a mais incerta
        selecionadas.append(restantes.pop(0))
        
        # Depois, balancear entre incerteza e diversidade
        while len(selecionadas) < n and restantes:
            melhor_score = -1
            melhor_candidato = None
            melhor_idx = -1
            
            for i, candidato in enumerate(restantes):
                # Score baseado na incerteza
                score_base = candidato['incerteza']
                
                # Penalizar se for muito similar aos j√° selecionados
                penalidade = 0
                for sel in selecionadas:
                    # Similaridade baseada na predi√ß√£o e incerteza
                    if (candidato['predicao'] == sel['predicao'] and 
                        abs(candidato['incerteza'] - sel['incerteza']) < 0.1):
                        penalidade += 0.2
                
                # Score final
                score_final = score_base * (1 - diversity_factor) - penalidade * diversity_factor
                
                if score_final > melhor_score:
                    melhor_score = score_final
                    melhor_candidato = candidato
                    melhor_idx = i
            
            if melhor_candidato:
                selecionadas.append(melhor_candidato)
                restantes.pop(melhor_idx)
            else:
                break
        
        return selecionadas
    
    def _get_prioridade_reason(self, analise):
        """
        Gera raz√£o da prioridade baseada na estrat√©gia.
        """
        if analise['incerteza'] > 0.7:
            if self.strategy == 'mc_dropout':
                return "Alta variabilidade nas predi√ß√µes estoc√°sticas"
            elif self.strategy == 'entropy':
                return "Alta entropia - distribui√ß√£o muito uniforme"
            elif self.strategy == 'margin':
                return "Margem muito pequena - classes muito pr√≥ximas"
            elif self.strategy == 'committee':
                return "Alta discord√¢ncia entre modelos do committee"
        elif analise['incerteza'] > 0.4:
            return "Incerteza moderada - anota√ß√£o valiosa"
        else:
            return "Baixa incerteza - menor prioridade"
    
    def visualize_uncertainty_distribution(self, novas_imagens, save_path=None):
        """
        Visualiza distribui√ß√£o de incertezas para an√°lise.
        
        Args:
            novas_imagens: Lista de imagens para analisar
            save_path: Caminho para salvar visualiza√ß√£o
        """
        logger.info("üìä Gerando visualiza√ß√£o da distribui√ß√£o de incertezas...")
        
        # Coletar incertezas
        incertezas = []
        confiancas = []
        
        for img in novas_imagens:
            resultado = self.predict_with_uncertainty(img)
            incertezas.append(resultado['uncertainty'])
            confiancas.append(resultado['confidence'])
        
        # Criar visualiza√ß√£o
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # Histograma de incertezas
        axes[0, 0].hist(incertezas, bins=20, alpha=0.7, color='orange', edgecolor='black')
        axes[0, 0].set_title('Distribui√ß√£o de Incertezas')
        axes[0, 0].set_xlabel('Incerteza')
        axes[0, 0].set_ylabel('Frequ√™ncia')
        axes[0, 0].axvline(np.mean(incertezas), color='red', linestyle='--', label=f'M√©dia: {np.mean(incertezas):.3f}')
        axes[0, 0].legend()
        
        # Histograma de confian√ßas
        axes[0, 1].hist(confiancas, bins=20, alpha=0.7, color='blue', edgecolor='black')
        axes[0, 1].set_title('Distribui√ß√£o de Confian√ßas')
        axes[0, 1].set_xlabel('Confian√ßa')
        axes[0, 1].set_ylabel('Frequ√™ncia')
        axes[0, 1].axvline(np.mean(confiancas), color='red', linestyle='--', label=f'M√©dia: {np.mean(confiancas):.3f}')
        axes[0, 1].legend()
        
        # Scatter plot: Incerteza vs Confian√ßa
        axes[1, 0].scatter(confiancas, incertezas, alpha=0.6, s=30)
        axes[1, 0].set_title('Incerteza vs Confian√ßa')
        axes[1, 0].set_xlabel('Confian√ßa')
        axes[1, 0].set_ylabel('Incerteza')
        axes[1, 0].grid(True, alpha=0.3)
        
        # Box plot comparativo
        data = [incertezas, confiancas]
        labels = ['Incerteza', 'Confian√ßa']
        axes[1, 1].boxplot(data, labels=labels)
        axes[1, 1].set_title('Comparativo: Incerteza vs Confian√ßa')
        axes[1, 1].set_ylabel('Valor')
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            logger.info(f"üìä Visualiza√ß√£o salva em: {save_path}")
        
        plt.show()
        
        return {
            'incerteza_media': np.mean(incertezas),
            'incerteza_std': np.std(incertezas),
            'confianca_media': np.mean(confiancas),
            'confianca_std': np.std(confiancas),
            'total_amostras': len(incertezas)
        }
    
    def export_suggestions(self, suggestions, filename='active_learning_suggestions.json'):
        """
        Exporta sugest√µes para arquivo JSON.
        
        Args:
            suggestions: Dicion√°rio de sugest√µes
            filename: Nome do arquivo
        """
        os.makedirs('outputs', exist_ok=True)
        
        filepath = os.path.join('outputs', filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(suggestions, f, indent=2, ensure_ascii=False)
        
        logger.info(f"üíæ Sugest√µes exportadas para: {filepath}")
        
        return filepath

if __name__ == "__main__":
    # Teste do m√≥dulo
    logger.info("üß™ Testando m√≥dulo de Active Learning...")
    
    # Criar modelo de teste
    modelo_teste = ClassificadorSujidade(num_classes=4)
    
    # Criar m√≥dulo active learning
    al_module = ActiveLearningModule(modelo_teste, strategy='mc_dropout')
    
    logger.info("‚úÖ M√≥dulo Active Learning testado com sucesso!")
